{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLC data downloading and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from downloader import download_file\n",
    "from IPython.core.display import clear_output\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUIDATA: /nfshome/pmb434/PUIdata\n"
     ]
    }
   ],
   "source": [
    "puidata = os.getenv(\"PUIDATA\")\n",
    "if puidata is None:\n",
    "    os.environ[\"PUIDATA\"] = \"{}/data/PUIdata\".format(os.getenv(\"HOME\"))\n",
    "    puidata = os.getenv(\"PUIDATA\")\n",
    "    print(\"Warning: PUIDATA environmental variable not found and set by code, please review!\")\n",
    "print(\"PUIDATA: {}\".format(puidata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define taxi zones for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download TLC taxi zones shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded.\n",
      "File already extracted.\n",
      "taxi_zones.zip contents in place, you can continue.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((933100.9183527103 192536.0856972019,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>(POLYGON ((1033269.243591294 172126.0078125, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1026308.769506663 256767.6975403726,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((992073.4667968601 203714.0759887695,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((935843.3104932606 144283.335850656, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
       "0         1    0.116357    0.000782           Newark Airport           1   \n",
       "1         2    0.433470    0.004866              Jamaica Bay           2   \n",
       "2         3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
       "3         4    0.043567    0.000112            Alphabet City           4   \n",
       "4         5    0.092146    0.000498            Arden Heights           5   \n",
       "\n",
       "         borough                                           geometry  \n",
       "0            EWR  POLYGON ((933100.9183527103 192536.0856972019,...  \n",
       "1         Queens  (POLYGON ((1033269.243591294 172126.0078125, 1...  \n",
       "2          Bronx  POLYGON ((1026308.769506663 256767.6975403726,...  \n",
       "3      Manhattan  POLYGON ((992073.4667968601 203714.0759887695,...  \n",
       "4  Staten Island  POLYGON ((935843.3104932606 144283.335850656, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download shapefile\n",
    "taxi_zones_files = download_file(url='https://s3.amazonaws.com/nyc-tlc/misc/taxi_zones.zip',\n",
    "                                 filename='taxi_zones.zip',\n",
    "                                 destination=puidata)\n",
    "\n",
    "#Read to GeoDataFrame\n",
    "taxi_zones_shp = gpd.read_file(taxi_zones_files[2])\n",
    "taxi_zones_shp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select taxi zones for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-73.97301487,  40.75827092, -73.935053  ,  40.79812922])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selected taxi zones\n",
    "taxi_zones = [140, 141, 262, 263, 75, 236, 237]\n",
    "taxi_zones_shp = taxi_zones_shp[taxi_zones_shp.LocationID.isin(taxi_zones)]\n",
    "\n",
    "#Get bounds to reduce trips dataframe for spatial join\n",
    "taxi_zones_shp.to_crs(epsg=4326, inplace=True)\n",
    "zone_bounds = taxi_zones_shp.total_bounds\n",
    "taxi_zones_shp.to_crs(epsg=2263, inplace=True)\n",
    "zone_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and process each month's trips dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>date</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>3607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.0</td>\n",
       "      <td>2014-07-02</td>\n",
       "      <td>4240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.0</td>\n",
       "      <td>2014-07-03</td>\n",
       "      <td>4342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.0</td>\n",
       "      <td>2014-07-04</td>\n",
       "      <td>3345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.0</td>\n",
       "      <td>2014-07-05</td>\n",
       "      <td>3144.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PULocationID        date  passenger_count\n",
       "0          75.0  2014-07-01           3607.0\n",
       "1          75.0  2014-07-02           4240.0\n",
       "2          75.0  2014-07-03           4342.0\n",
       "3          75.0  2014-07-04           3345.0\n",
       "4          75.0  2014-07-05           3144.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Needed for months with wrong formatting (2 empty columns at the end)\n",
    "columns = ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
    "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
    "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
    "       'total_amount','error','error2']\n",
    "\n",
    "#Empty Dataframe to fill with data\n",
    "all_months = pd.DataFrame(columns=['PULocationID', 'date', 'passenger_count'])\n",
    "\n",
    "#Counter for display\n",
    "i=0\n",
    "\n",
    "#Nested loop: year + month\n",
    "for y in range(2014, 2019):\n",
    "    \n",
    "    for m in range(1,13):\n",
    "        \n",
    "        #Get only the last four years, ending in Jul 2018 (latest available dataset)\n",
    "        if (y == 2018 and m > 6) or (y == 2014 and m < 7):\n",
    "            continue\n",
    "         \n",
    "        i = i+1\n",
    "        \n",
    "        #Set filename and url\n",
    "        month = str(m) if len(str(m)) == 2 else '0' + str(m)\n",
    "        filename = 'yellow_tripdata_' + str(y) + '-' + month + '.csv'\n",
    "        url = \"https://s3.amazonaws.com/nyc-tlc/trip+data/\" + filename\n",
    "        \n",
    "        print('File {}: {}'.format(i, filename))\n",
    "        \n",
    "        #Check if we already processed this month\n",
    "        if os.path.isfile(puidata + '/yellowtaxi_partial_{}-{}.csv'.format(y,month)):\n",
    "            \n",
    "            print('Already processed, loading partial file')\n",
    "            \n",
    "            all_months = all_months.append(\n",
    "                pd.read_csv(puidata + '/yellowtaxi_partial_{}-{}.csv'.format(y,month), parse_dates=[1]))\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            #Download month dataset\n",
    "            path = download_file(url=url, filename=filename, destination=puidata)\n",
    "\n",
    "            print('Reading')\n",
    "\n",
    "            #Months with wrong column formatting\n",
    "            if y == 2016 and m > 6:\n",
    "                month_df = pd.read_csv(path, parse_dates=[1], infer_datetime_format=True,\n",
    "                               index_col=False, names=columns, skiprows=[0])\n",
    "            else:\n",
    "                month_df = pd.read_csv(path, parse_dates=[1], infer_datetime_format=True, skipinitialspace=True)\n",
    "            \n",
    "            #Before Jul 2016 data has latlong for each trips pickup and drop off location\n",
    "            #Convert to taxi zones - We are only using pickup location\n",
    "            if (y < 2016) or (y == 2016 and m < 7):\n",
    "                \n",
    "                month_select = month_df[month_df.pickup_longitude.between(zone_bounds[0], zone_bounds[2]) & \\\n",
    "                                        month_df.pickup_latitude.between(zone_bounds[1], zone_bounds[3])]\n",
    "\n",
    "\n",
    "                print('Converting to GeoDataFrame')\n",
    "\n",
    "                geometry = [Point(xy) for xy in zip(month_select.pickup_longitude, month_select.pickup_latitude)]\n",
    "                crs = {'init': 'epsg:4326'}\n",
    "                month_select = gpd.GeoDataFrame(month_select, crs=crs, geometry=geometry)\n",
    "                month_select.to_crs(epsg=2263, inplace=True)\n",
    "\n",
    "                print('Spatial join')\n",
    "\n",
    "                month_select = gpd.sjoin(month_select, taxi_zones_shp)\n",
    "                month_select.rename(columns={'LocationID':'PULocationID'}, inplace=True)\n",
    "\n",
    "            else:\n",
    "                \n",
    "                month_select = month_df[month_df.PULocationID.isin(taxi_zones)]\n",
    "                \n",
    "            print('Grouping')\n",
    "\n",
    "            #Column changed name at some point\n",
    "            if 'tpep_pickup_datetime' in month_select.columns:\n",
    "                month_select['date'] = month_select.tpep_pickup_datetime.dt.date\n",
    "            else:\n",
    "                month_select['date'] = month_select.pickup_datetime.dt.date\n",
    "\n",
    "            #Group by date and pickup taxi zone ID -> Total passengers per day\n",
    "            month_grouped =  month_select.groupby(['PULocationID','date'], as_index=False)[['passenger_count']].sum()\n",
    "            \n",
    "            #Remove dates out of range (happens in some months)\n",
    "            month_grouped = month_grouped[(pd.datetime(y, m, 1).date() <= month_grouped.date) & \\\n",
    "                                          (month_grouped.date < (pd.datetime(y, m, 1) + pd.DateOffset(months=1)).date())]\n",
    "            \n",
    "            print('Saving partial file')\n",
    "            \n",
    "            #Save partial file for convenience\n",
    "            month_grouped.to_csv(puidata + '/yellowtaxi_partial_{}-{}.csv'.format(y,month), index=False)\n",
    "\n",
    "            #Append processed data to DF with all months\n",
    "            all_months = all_months.append(month_grouped)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        time.sleep(1)\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "#Save all months\n",
    "all_months.to_csv(puidata + '/yellowtaxi_all.csv', index=False)\n",
    "all_months.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263.0    1461\n",
       "262.0    1461\n",
       "237.0    1461\n",
       "236.0    1461\n",
       "141.0    1461\n",
       "140.0    1461\n",
       "75.0     1461\n",
       "Name: PULocationID, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_months.PULocationID.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python3",
   "language": "python",
   "name": "pui2016_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
